{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Linear Algebra\n",
    "\n",
    "Linear Algebra is an important field of mathematics for artificial intelligence. Many AI algorithms that we will cover in this course are expressed or framed in terms of vectors and matrices - the primary objects of study of linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "* A **tensor** is an $n$-dimensional array. The entries in a tensor, also called its components or elements, are drawn from some set. For the most part in this course, we will manipulate tensors defined over the set of real numbers, $\\mathbb{R}$, or the set of integers, $\\mathbb{Z}$\n",
    "* The number of dimensions of a tensor is called its **rank**.\n",
    "    * A rank 0 tensor is called a scalar, e.g. $2$, $3.8989$. By convention, scalars are denoted by common letter variables, e.g. $x = 3.8989$\n",
    "    * A rank 1 tensor is called a (column) vector, e.g. $\\begin{bmatrix}2.1 \\\\ 3.4\\end{bmatrix}$. By convention, we use common letters to denote vectors or common letter with arrows overhead, e.g. $x = \\begin{bmatrix}2.1 \\\\ 3.4\\end{bmatrix}$ or $\\vec{x} = \\begin{bmatrix}2.1 \\\\ 3.4\\end{bmatrix}$   Vectors are often used to represent directions through space or points in space.\n",
    "    * A rank 2 tensor is called a matrix, e.g. $\\begin{bmatrix}2 & 3 \\\\ 4 & 5\\end{bmatrix}$. By convention, we use capital letters to denote matrices, e.g. $M = \\begin{bmatrix}2 & 3 \\\\ 4 & 5\\end{bmatrix}$\n",
    "* While rank tells us the number of dimensions, each dimension has a size. We need to describe the set of tensors drawn from a particular set with each dimension having a particular size. By convention, a vector of size $n$ over the set of real numbers is said to be an element of the set $\\mathbb{R}^n$, and a matrix with $n$ rows and $m$ columns over the set of real numbers is said to be an element of the set $\\mathbb{R}^{n \\times m}$. \n",
    "* Note that vectors of size $n$ can be descibed as being matrices of size $n \\times 1$ and are, at least computationally, are sometimes treated as such. Note, however, that vectors are usually used to express concepts different from that of matricies. Matrices are usually used (including in an AI context) as a way of expressing a special type of function called a linear mapping, while vectors are used to describe directions or \"points\" in space.\n",
    "*  The $i$<sup>th</sup> component of a vector $x$ is denoted as $x_i$\n",
    "* The component of a matrix $M$ at row $i$ and column $j$ is denoted as either $M_{ij}$ or $m_{ij}$\n",
    "* The $j$<sup>th</sup> column of a matrix $M$ is denoted as $M_{:,j}$ or $m_{j}$\n",
    "* The $j$<sup>th</sup> row of a matrix $M$ is denoted as $M_{j,:}$ or $m^{T}_{j}$\n",
    "* Suppose that we have numbers $x_1, x_2, x_3, \\ldots x_n$. If $y = a_1x_1 + a_2x_2 + a_3x_3 + \\ldots + a_nx_n$, where $x_1, x_2, x_3, \\ldots x_n$ are some other numbers, then $y$ is a linear combination of  $x_1, x_2, x_3, \\ldots x_n$\n",
    "* A matrix is square if it has the same number of rows and columns\n",
    "* The vector $\\mathbf{0}$ is a special vector containing only 0s and $\\mathbf{1}$ is a special vector containing only 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Give an example of a tensor from the following sets:\n",
    "    1. $\\mathbb{R}^2$\n",
    "    2. $\\mathbb{Z}^{3 \\times 3}$\n",
    "    3. $\\mathbb{R}^{5 \\times 1}$\n",
    "    4. $\\mathbb{R}^{1 \\times 5}$\n",
    "    5. $\\mathbb{R}$\n",
    "2. To what set do the following tensors belong?\n",
    "    1. $\\begin{bmatrix}2 & 5 & 5.34 \\\\ 3 & 4.5 & -1.2\\end{bmatrix}$\n",
    "    2. $\\begin{bmatrix}2 \\\\ 5\\end{bmatrix}$\n",
    "    2. $\\begin{bmatrix}2 & 5\\end{bmatrix}$\n",
    "3. Consider the matrix $$M = \\begin{bmatrix}1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}$$\n",
    "    1. What is $M_{11}$ ?\n",
    "    2. What is $m_{1}$ ?\n",
    "    3. What is $m^{T}_{1}$ ?\n",
    "4. Consider the vector $$x = \\begin{bmatrix}1 \\\\ 2 \\\\ 3 \\end{bmatrix}$$\n",
    "    1. What is $x_{1}$ ?\n",
    "    2. What is $x_{3}$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "The `numpy` and `torch` libraries give us facilities to manipulate and store tensors. We shall look at how to create them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import numpy library\n",
    "\n",
    "x_row = np.array([1, 2, 3]) # a row vector i.e. 1 x 3 matrix\n",
    "x_col = np.array([[1], [2], [3]]) # a vector \n",
    "M = np.array([[1, 2, 3], [4, 5, 6]]) # a 2 x 3  matrix\n",
    "\n",
    "n, m = M.shape\n",
    "print(n)\n",
    "print(m)\n",
    "\n",
    "M_11 = M[1][1] # Access component\n",
    "M_11_another = M[1,1] # Access component\n",
    "print(M_11)\n",
    "print(M_11_another)\n",
    "\n",
    "# column vectors are treated as matrices\n",
    "x_1 = x_col[1][0]\n",
    "x_2 = x_col[2][0]\n",
    "\n",
    "M_1 = M[:,1] # column slice\n",
    "M_T_1 = M[1,:] # row slice\n",
    "\n",
    "ones_3_3 = np.ones((3, 3)) # 3 x 3 matrix of ones\n",
    "zeros_3_3 = np.zeros((3, 3)) # 3 x 3 matrix of ones\n",
    "ones_3 = np.ones((3, 1)) # vector with ones\n",
    "zeros_3 = np.ones((3, 1)) # vector with ones\n",
    "M_with_ones = np.ones_like(M) # create a matrix with all ones, with the same size as M\n",
    "M_with_zeros = np.zeros_like(M) # create a matrix with all zeroes, with the same size as M\n",
    "\n",
    "sep = \"=========================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate random vectors are matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63285569 0.59211819 0.01850163]\n",
      " [0.45281911 0.26457497 0.00597591]]\n",
      "=========================\n",
      "[[0.79794057 0.93664194 0.58856676]]\n",
      "=========================\n",
      "[0.38144335 0.21832541 0.10261183]\n",
      "=========================\n",
      "[0.0485009  0.71376719 0.70346129 0.89056215 0.25419393 0.49464767\n",
      " 0.08818572 0.67597223 0.87221094 0.80835031]\n",
      "[[0.0485009  0.71376719 0.70346129 0.89056215 0.25419393 0.49464767\n",
      "  0.08818572 0.67597223 0.87221094 0.80835031]]\n",
      "[[0.0485009  0.71376719 0.70346129 0.89056215 0.25419393 0.49464767\n",
      "  0.08818572 0.67597223 0.87221094 0.80835031]]\n",
      "[[0.0485009  0.71376719]\n",
      " [0.70346129 0.89056215]\n",
      " [0.25419393 0.49464767]\n",
      " [0.08818572 0.67597223]\n",
      " [0.87221094 0.80835031]]\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "M1 = np.random.random((2, 3)) # a random 2 x 3 matrix\n",
    "\n",
    "\n",
    "print(M1)\n",
    "\n",
    "print(sep)\n",
    "\n",
    "v1 = np.random.random((1, 3)) # a random column vector\n",
    "\n",
    "print(v1)\n",
    "\n",
    "print(sep)\n",
    "v2 = np.random.random(3) # a random row vector\n",
    "\n",
    "print(v2)\n",
    "print(sep)\n",
    "\n",
    "# can also reshape matrices and vectors\n",
    "\n",
    "v3 = np.random.random(10)\n",
    "v3_col = v3.reshape((10, 1))\n",
    "v3_col_another_way = v3.reshape((10, -1)) # -1 autofills\n",
    "M2 = v3.reshape((5, 2))\n",
    "\n",
    "print(v3)\n",
    "print(v3_col)\n",
    "print(v3_col_another_way)\n",
    "print(M2)\n",
    "\n",
    "print(sep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on Vectors and Matrices\n",
    "There are several operations that can be performed on vectors and matrices, and many familiar operations have vector and matrix equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition and Hadamard Product\n",
    "\n",
    "Addition and Hadamard Product are examples of component-wise binary operations. In such operations, both operands must be of the same size. The output is the same size as the inputs. They are defined as follows:\n",
    "\n",
    "#### Addition\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "a_{11} & a_{12} & \\ldots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & \\ldots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} & a_{n2} & \\ldots & a_{nm} \n",
    "\\end{bmatrix}\n",
    "$ $+$ $\n",
    "\\begin{bmatrix} \n",
    "b_{11} & b_{12} & \\ldots & b_{1m} \\\\ \n",
    "b_{21} & b_{22} & \\ldots & b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "b_{n1} & b_{n2} & \\ldots & b_{nm} \n",
    "\\end{bmatrix}\n",
    "$ $=$ $\\begin{bmatrix} \n",
    "a_{11} + b_{11} & a_{12} + b_{12} & \\ldots & a_{1m}  + b_{1m}\\\\ \n",
    "a_{21} + b_{21} & a_{22} + b_{22} & \\ldots & a_{2m} + b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} + b_{n1} & a_{n2} + b_{n2} & \\ldots & a_{nm} + b_{nm} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Or more succintly, $(A + B)_{ij} = a_{ij} + b_{ij}$\n",
    "\n",
    "### Hadamard Product\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "a_{11} & a_{12} & \\ldots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & \\ldots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} & a_{n2} & \\ldots & a_{nm} \n",
    "\\end{bmatrix}\n",
    "$ $\\odot$\n",
    "$\\begin{bmatrix} \n",
    "b_{11} & b_{12} & \\ldots & b_{1m} \\\\ \n",
    "b_{21} & b_{22} & \\ldots & b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "b_{n1} & b_{n2} & \\ldots & b_{nm} \n",
    "\\end{bmatrix}$\n",
    " $=$ $\\begin{bmatrix} \n",
    "a_{11} \\cdot b_{11} & a_{12} \\cdot b_{12} & \\ldots & a_{1m}  \\cdot b_{1m}\\\\ \n",
    "a_{21} \\cdot b_{21} & a_{22} \\cdot b_{22} & \\ldots & a_{2m} \\cdot b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} \\cdot b_{n1} & a_{n2} \\cdot b_{n2} & \\ldots & a_{nm} +\\cdot b_{nm} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Or more succintly, $(A \\odot B)_{ij} = a_{ij} \\cdot b_{ij}$\n",
    "\n",
    "\n",
    "The operations on vectors are defined accordingly. Note that these operations are commutative and associative.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84155044 0.10350133]\n",
      " [0.67842369 0.02882484]\n",
      " [0.09323786 0.69758931]]\n",
      "+\n",
      "[[0.22109236 0.51558658]\n",
      " [0.72054356 0.70079357]\n",
      " [0.95047241 0.36641164]]\n",
      "=\n",
      "[[1.0626428  0.61908791]\n",
      " [1.39896725 0.72961841]\n",
      " [1.04371027 1.06400095]]\n",
      "=========================\n",
      "[[0.84155044 0.10350133]\n",
      " [0.67842369 0.02882484]\n",
      " [0.09323786 0.69758931]]\n",
      "+\n",
      "[[0.22109236 0.51558658]\n",
      " [0.72054356 0.70079357]\n",
      " [0.95047241 0.36641164]]\n",
      "=\n",
      "[[0.18606037 0.0533639 ]\n",
      " [0.48883382 0.02020026]\n",
      " [0.08862002 0.25560484]]\n"
     ]
    }
   ],
   "source": [
    "# numpy code\n",
    "\n",
    "A = np.random.random((3, 2))\n",
    "B = np.random.random((3, 2))\n",
    "\n",
    "print(A)\n",
    "print('+')\n",
    "print(B)\n",
    "print('=')\n",
    "print(A + B)\n",
    "\n",
    "print(sep)\n",
    "\n",
    "print(A)\n",
    "print('+')\n",
    "print(B)\n",
    "print('=')\n",
    "print(A * B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Multiplication and Addition\n",
    "\n",
    "You can also mulitply and add each component of a vector or matrix by a scalar\n",
    "\n",
    "### Scalar Multiplication\n",
    "\n",
    "$\\alpha\\begin{bmatrix} \n",
    "a_{11} & a_{12} & \\ldots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & \\ldots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} & a_{n2} & \\ldots & a_{nm} \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "\\alpha \\cdot a_{11} & \\alpha \\cdot a_{12} & \\ldots & \\alpha \\cdot a_{1m} \\\\ \n",
    "\\alpha \\cdot a_{21} & \\alpha \\cdot a_{22} & \\ldots & \\alpha \\cdot a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "\\alpha \\cdot a_{n1} & \\alpha \\cdot a_{n2} & \\ldots &  \\alpha \\cdot a_{nm} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Or more succintly, $(\\alpha A)_{ij} = \\alpha \\cdot A_{ij}$\n",
    "\n",
    "### Scalar Addition\n",
    "$b + \\begin{bmatrix} \n",
    "a_{11} & a_{12} & \\ldots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & \\ldots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "a_{n1} & a_{n2} & \\ldots & a_{nm} \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "b + a_{11} & b + a_{12} & \\ldots & b + a_{1m} \\\\ \n",
    "b + a_{21} & b + a_{22} & \\ldots & b + a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots \\\\ \n",
    "b + a_{n1} & b + a_{n2} & \\ldots &  b + a_{nm} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Or more succintly, $(b + A)_{ij} = b + A_{ij}$\n",
    "By convention, we tend to write it as $A + b$\n",
    "\n",
    "The operations on vectors are defined accordingly. Note that these operations are commutative and associative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37619272 0.34653864]\n",
      " [0.30175993 0.43102818]\n",
      " [0.55410546 0.60680518]\n",
      " [0.22476439 0.15351535]\n",
      " [0.17032058 0.11558036]]\n",
      "=========================\n",
      "[[0.75238544 0.69307728]\n",
      " [0.60351987 0.86205636]\n",
      " [1.10821093 1.21361035]\n",
      " [0.44952879 0.3070307 ]\n",
      " [0.34064116 0.23116071]]\n",
      "=========================\n",
      "[[2.37619272 2.34653864]\n",
      " [2.30175993 2.43102818]\n",
      " [2.55410546 2.60680518]\n",
      " [2.22476439 2.15351535]\n",
      " [2.17032058 2.11558036]]\n"
     ]
    }
   ],
   "source": [
    "M1 = np.random.random((5, 2))\n",
    "\n",
    "print(M1)\n",
    "print(sep)\n",
    "print(2 * M1)\n",
    "print(sep)\n",
    "print(2 + M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "\n",
    "The transpose operation flips columns and rows\n",
    "\n",
    "Suppose $M = \\begin{bmatrix}2 & 3 & 4\\\\ 5 & 6 & 7\\end{bmatrix}$, then its transpose, denoted as $M^T$ is\n",
    "$M^{T} = \\begin{bmatrix}2 & 5 \\\\ 3 & 6\\\\ 4 & 7\\end{bmatrix}$\n",
    "\n",
    "Sometimes for convenience, we write column vectors as the tranpose of row vectors. For example, instead of writing $v = \\begin{bmatrix} 2 \\\\ 3 \\\\ 4 \\end{bmatrix}$, we write $v = \\begin{bmatrix} 2 & 3 & 4 \\end{bmatrix}^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13983724 0.95807682 0.17524652]\n",
      " [0.88026113 0.24211687 0.52199909]]\n",
      "=========================\n",
      "[[0.13983724 0.88026113]\n",
      " [0.95807682 0.24211687]\n",
      " [0.17524652 0.52199909]]\n"
     ]
    }
   ],
   "source": [
    "M1 = np.random.random((2, 3))\n",
    "print(M1)\n",
    "print(sep)\n",
    "print(M1.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm \n",
    "\n",
    "The norm of a vector or matrix is the some notion of length on a vector or matrix. The most familiar norm is the euclidean norm or $\\mathcal{l}_{2}$ norm. The euclidean norm of a vector $v$ of size $n$ is denoted as either $||v||_{2}$ or as just $||v||$, and is defined as follows:\n",
    "$$||v||_{2} = \\sqrt{\\sum_{i=1}^{n} v_{i}^{2}}$$. In general the $\\mathcal{l}_{p}$ norm of a vector is \n",
    "$$||v||_{p} = \\left({\\sum_{i=1}^{n} v_{i}^{p}}\\right)^{\\frac{1}{p}}$$\n",
    "\n",
    "The euclidean distance between two vectors is the euclidean norm of their component-wise difference, i.e. $$d(u, v) = ||u - v||$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26524953]\n",
      " [0.55767317]\n",
      " [0.89475216]]\n",
      "=========================\n",
      "[[0.88371673]\n",
      " [0.44631044]\n",
      " [0.04857381]]\n",
      "=========================\n",
      "1.0871697679555463\n",
      "0.9912152565510658\n",
      "1.0540024360138136\n"
     ]
    }
   ],
   "source": [
    "v = np.random.random((3, 1))\n",
    "u = np.random.random((3, 1))\n",
    "norm_v = np.linalg.norm(v, 2)\n",
    "norm_u = np.linalg.norm(u, 2)\n",
    "dist_uv = np.linalg.norm(u - v, 2)\n",
    "print(v)\n",
    "print(sep)\n",
    "print(u)\n",
    "print(sep)\n",
    "print(norm_v)\n",
    "print(norm_u)\n",
    "print(dist_uv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "If we have matrices of compatible dimensions, we can mutliply them. For two matrices to be compatible for matrix mutliplication (abbrev. matul), the number of columns of the first be the same as the number of the rows in the second. The output has the number of rows from the first and the number of columns from the second. \n",
    "\n",
    "Consider that we have two matrices A and B of dimensions $m \\times n$ and $n \\times p$ respectively, the their matrix product is defined as:\n",
    "\n",
    "$$C_{ij} = \\sum_{k=1}^{n} A_{ik} \\cdot B_{kj}$$\n",
    "\n",
    "For example, suppose we have two matrices $A$ and $B$ defined as follows\n",
    "\n",
    "$$A = \\begin{bmatrix}2 & 3 \\\\ 4 & 5\\end{bmatrix}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$B = \\begin{bmatrix}1 & 2 & 3\\\\ 4 & 5 & 6\\end{bmatrix}$$\n",
    "\n",
    "Hence, $C = AB$, is \n",
    "$$C = \\begin{bmatrix}14 & 19 & 24 \\\\ 24 & 33 & 42\\end{bmatrix}$$\n",
    "\n",
    "Note that matmul is not commutative, but is associative and distributive. Matrix Multiplication is actually a form of function composition over linear mappings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 19 24]\n",
      " [24 33 42]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[2, 3], [4, 5]])\n",
    "y = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(x @ y) # @ is the symbol for matrix multiplication in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-Vector Products\n",
    "\n",
    "Suppose that we have two vectors $u$ and $v$ $\\in \\mathbb{R}^{n}$. There are two main ways we can defined a product in terms of $u$ and $v$: inner product and outer product.\n",
    "\n",
    "### Inner Product\n",
    "The inner product is also called the dot product. Treating vectors $u$ and $v$ as matricies, their dot product is defined as follows:\n",
    "\n",
    "$$u \\bullet v = u^{T}v = u_{1}v_{1} + u_{2}v_{2} + \\ldots u_{n}v_{n}$$ \n",
    "\n",
    "The dot product is useful as it has a geometric interpretation:\n",
    "$$cos ~ \\theta = \\frac{u \\bullet v}{\\vert\\vert u \\vert\\vert \\vert\\vert v \\vert\\vert}$$\n",
    "\n",
    "where $\\theta$ is the angle between vectors $u$ and $v$\n",
    "\n",
    "### Outer Product\n",
    "The outer product between vectors $u$ and $v$ are defined as $x \\otimes v = xv^{T}$. One way to remember the difference between the inner and outer product is that the adjective indicates the placement of the tranpose operation. If it is inside of the vectors it is an inner product, if it is on the right vector it is an outer product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29590262]\n",
      " [0.68956713]\n",
      " [0.30488254]]\n",
      "=========================\n",
      "[[0.42884117]\n",
      " [0.98008657]\n",
      " [0.35413682]]\n",
      "=========================\n",
      "[[0.91070084]]\n",
      "=========================\n",
      "[[0.12689522 0.29001018 0.10479001]\n",
      " [0.29571477 0.67583549 0.24420111]\n",
      " [0.13074618 0.29881129 0.10797013]]\n",
      "=========================\n",
      "[[0.29590262 0.29590262 0.29590262]\n",
      " [0.68956713 0.68956713 0.68956713]\n",
      " [0.30488254 0.30488254 0.30488254]]\n"
     ]
    }
   ],
   "source": [
    "u = np.random.random((3, 1))\n",
    "v = np.random.random((3, 1))\n",
    "ones = np.ones_like(u)\n",
    "\n",
    "print(u)\n",
    "print(sep)\n",
    "print(v)\n",
    "print(sep)\n",
    "print(np.transpose(u) @ v)\n",
    "print(sep)\n",
    "print(u @ np.transpose(v))\n",
    "print(sep)\n",
    "print(u @ np.transpose(ones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-Vector Multiplication\n",
    "\n",
    "We can also multiply matrices and vectors of appropriate dimensions. Recall that computationally, we can treat vectors as thourh they are matrices with a single column. Suppose that we have an $m \\times n$ matrix $M$ and a vector of size $n$ called $x$, i.e. $M \\in \\mathbb{R}^{m \\times n} \\text{ and } x \\in \\mathbb{R}^{n}$. The operation $Mx$ will yield a vector in $\\mathbb{R}^{m}$.\n",
    "\n",
    "For example, suppose\n",
    "\n",
    "$$M = \\begin{bmatrix}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$x = \\begin{bmatrix}1 \\\\ 2 \\\\ 3\\end{bmatrix}$$\n",
    "\n",
    "Then $Mx$ is\n",
    "$$\\begin{bmatrix}1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix} \\begin{bmatrix}1 \\\\ 2 \\\\ 3\\end{bmatrix} = $$\n",
    "$$\\begin{bmatrix}1 + 4 + 9 \\\\ 4 + 10 + 18\\end{bmatrix} = \\begin{bmatrix}14 \\\\ 32\\end{bmatrix}$$\n",
    "\n",
    "Notice that the input has the same number of columns of $M$ and the output has the same number of rows. Recall that we mentioned that matrices encode functions; hence we can see that an $m \\times n$ matrix encodes a function with the domain $\\mathbb{R}^{n}$ and the range $\\mathbb{R}^{m}$, i.e. $M: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8512076  0.86231019 0.69342643]\n",
      " [0.39889822 0.84434217 0.41829395]]\n",
      "=========================\n",
      "[[0.85895431]\n",
      " [0.16611442]\n",
      " [0.87856824]]\n",
      "=========================\n",
      "[[1.48361303]\n",
      " [0.85039254]]\n"
     ]
    }
   ],
   "source": [
    "M = np.random.random((2, 3))\n",
    "x = np.random.random((3, 1))\n",
    "print(M)\n",
    "print(sep)\n",
    "print(x)\n",
    "print(sep)\n",
    "print(M @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transformation\n",
    "An affine transformation is a special transformation of the form $Ax + b$ where $A \\in \\mathbb{R}^{m \\times n}, x \\in \\mathbb{R}^{n}, b \\in \\mathbb{R}$. Many AI algorithms use affine transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Inverse\n",
    "Suppose we have $Ax = y$, the matrix $A^{-1}$, called the inverse of $A$ is a special matrix where $A^{-1}y = x$. Note that $A$ and $A^{-1}$ have the same dimensions and $A$ must be square. Since matrices are functions, you can think of it as an inverse funciton. Just like other functions, not every matrix has an inverse. Their computation is beyond the scope of the course, but you should be aware of its existence.\n",
    "\n",
    "For non-square matrices, there are pseudo-inverses such as the Moore-Penrose Pseudo-inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [5 6]]\n",
      "=========================\n",
      "[[-2.          1.        ]\n",
      " [ 1.66666667 -0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "M = np.array([[2, 3], [5, 6]])\n",
    "print(M)\n",
    "print(sep)\n",
    "print(np.linalg.inv(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrices\n",
    "\n",
    "Identity Matrices are square matrices with 1 on its leading diagonal. An idenity matrix of size $n \\times n$ is denoted by $I_{n}$. For example,\n",
    "\n",
    "$$I_{2} = \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "Identity matrices are special as $AI_{n} = A$ for all square matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "I_3 = np.eye(3)\n",
    "print(I_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
